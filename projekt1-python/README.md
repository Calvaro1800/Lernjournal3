# ğŸ“Š Portfolio Optimizer â€” alvarchr â€” MDM FS2025

Ein Projekt gemacht fÃ¼r das Modul **Model Deployment & Maintenance** an der ZHAW (FrÃ¼hsemester 2025).  
ğŸ‘¤ Name: alvarchr  
ğŸ“˜ Modul: MDM FS2025  
ğŸ“ Betreuer: Prof. Adrian Moser

---

Willkommen zu meinem Projekt **Portfolio Optimizer mit KI**, das ich im Rahmen des Moduls *Model Deployment & Maintenance (MDM)* an der ZHAW entwickelt habe.  
Dieses Projekt war eine echte Reise â€“ mit vielen Herausforderungen, Frustmomenten, Lerneffekten und Stolz am Ende!

---

## ğŸ¯ Ziel des Projekts

Ich wollte ein echtes **Finanz-Tool mit KI** bauen, das:

- echte **Aktien-Daten** holt und automatisch analysiert
- die Performance einzelner Titel prognostiziert
- das Portfolio bewertet (Sharpe Ratio)
- und sogar **Finanzempfehlungen im Stil eines Beraters** gibt

Mein Ziel war, eine Web-App zu bauen, die technisch anspruchsvoll, aber fÃ¼r Nutzer einfach zu bedienen ist â€“ komplett automatisiert, interaktiv und mit kÃ¼nstlicher Intelligenz.

---

## ğŸ§© Funktionen (Ãœbersicht)

| Kategorie                | Funktion                                                                 |
|--------------------------|--------------------------------------------------------------------------|
| ğŸ“ˆ Scraping              | Holt automatisch Top Gainers von Yahoo Finance                           |
| ğŸ“° News & Sentiment      | Scrapt Finanznachrichten + Sentimentanalyse mit Transformers-Modell      |
| ğŸ“‰ Regression IA         | Regressionsmodell prognostiziert Performance von Aktien                  |
| ğŸ§  LLM Finanzberater     | GPT-2 gibt Empfehlungen wie ein virtueller Berater (Otto)                |
| ğŸ“Š Sharpe Ratio          | Bewertet Portfolio-Risiko vs. Rendite                                    |
| ğŸ§‘â€ğŸ’» Flask UI            | Web-App mit Suche, Buy/Sell, Charts, Upload & LLM-Fragen                  |
| ğŸ“… Termin vereinbaren    | Berater wÃ¤hlen (Ray Dalio, Gekkoâ€¦) mit Bild + BestÃ¤tigungsnachricht     |
| â° Automatisierung        | CRON-Scheduling + GitHub Actions automatisieren Daten & Analyse         |
| ğŸ§ª Unit Tests            | Testabdeckung fÃ¼r Modelle, LLM, Scraper und Sentiment                   |
| ğŸ³ Docker                | Lokales Docker-Image verfÃ¼gbar (Azure-Deployment in Arbeit)             |

---

## ğŸ’¥ Herausforderungen (technisch & persÃ¶nlich)

Ich komme ursprÃ¼nglich **nicht aus dem Python- oder DevOps-Bereich**.  
Deshalb war dieses Projekt fÃ¼r mich eine doppelte Herausforderung.

### ğŸ”¹ MongoDB
- IP-Ranges, DNS-Probleme, SSL Errors, `tlsAllowInvalidCertificates` â€“ es war ein harter Einstieg
- Aber am Ende konnte ich Ã¼ber Compass, `pymongo` und `.env` alles stabil verbinden
<img width="946" alt="Screenshot 2025-05-25 at 23 15 22" src="https://github.com/user-attachments/assets/b3b6738c-ea70-49e7-9889-eb5450f1dfdb" />

### ğŸ”¹ Scraping
- Playwright hat anfangs nicht funktioniert â†’ ich bin auf `requests + BeautifulSoup` umgestiegen
- Yahoo Finance Ã¤ndert oft die HTML-Struktur â†’ ich musste regelmÃ¤ÃŸig Debuggen
- Duplikate, Timeout-Fehler, Unicode-Fehlerâ€¦ ich hab alles gesehen

### ğŸ”¹ Modelle
- Ich musste lernen, wie man `transformers`, `sklearn` und lokale Modelle integriert
- Regression + Sentiment + GPT-2 mussten miteinander kommunizieren
- Ich habe alle Modelle **manuell getestet** und `test_models.py` geschrieben

### ğŸ”¹ Flask & Frontend
- Ich hatte keine Erfahrung mit Flask oder Jinja2
- Trotzdem habe ich eine App mit **Charts, Pie Diagrammen, Autocomplete und Forms** gebaut
- Ich habe Bootstrap, Chart.js und JS-Funktionen kombiniert â€“ es war intensiv

Prototype:
  <img width="327" alt="Screenshot 2025-05-25 at 23 15 01" src="https://github.com/user-attachments/assets/2af5edb3-d786-46f1-9a58-b572df0d2f47" />
End Version:
<img width="769" alt="Screenshot 2025-05-25 at 23 21 07" src="https://github.com/user-attachments/assets/61e03d58-6d96-4d27-a178-d49f1fc68aa5" />

### ğŸ”¹ GitHub Actions
- Ich habe YAML-Dateien selbst geschrieben fÃ¼r automatisches Scraping, Build & Test
- Debugging war schwer, vor allem mit Secrets (Mongo URI, HF Token)
<img width="725" alt="Screenshot 2025-05-25 at 23 23 17" src="https://github.com/user-attachments/assets/f45ff99e-a12c-4344-8685-5a2e853201bc" />

### ğŸ”¹ Docker & macOS Probleme
- Nach einem **macOS Sequoia Update** konnte ich Docker Desktop **nicht mehr Ã¶ffnen**
- Ich habe mit **Colima** gearbeitet, um mein Projekt trotzdem containerisieren zu kÃ¶nnen
- Ich konnte mein Image lokal bauen & ausfÃ¼hren (`port 5151`)
- Das **Azure Deployment** war leider am Tag des Screencasts noch nicht abgeschlossen
![Screenshot 2025-05-25 at 23 29 09](https://github.com/user-attachments/assets/2e3a7fe7-ef62-4a0e-887f-ed99f64f18c8)

---

## ğŸ§  Meine Learnings

Ich habe in diesem Projekt gelerntâ€¦

- wie man **Daten automatisiert sammelt und speichert**
- wie man **Modelle trainiert, verbindet und testet**
- wie man eine **echte Web-App mit Flask und MongoDB** baut
- wie man **Fehler systematisch debuggt**
- und vor allem: **dran bleiben**, auch wenn es schwer wird

Ich bin stolz, dass ich dieses Projekt mit null Vorwissen zu einem funktionierenden Prototypen gebracht habe.

---

## ğŸ§ª Tests & QualitÃ¤t

Ich habe eigene Tests geschrieben, z.B.:

- `test_models.py` â†’ Sharpe Ratio, Klassifikation, Regression  
- `test_sentiment.py` â†’ Korrektheit der Sentimentanalyse  
- `test_ask_model.py` â†’ Antworten des LLM richtig formatiert  
- `test_update_all_stocks.py` â†’ Kontrolle des Scraping-Outputs

ZusÃ¤tzlich:

- `debug_llm.py` â†’ zum manuellen Testen von Otto (GPT-2)  
- `compute_avg_sentiment.py` â†’ berechnet tÃ¤glichen Sentiment-Schnitt aus MongoDB  

---

## ğŸ“‚ Projektstruktur (technisch)

```bash
projekt1-python/
â”‚
â”œâ”€â”€ app.py                     # Hauptserver (Flask)
â”œâ”€â”€ core/                      # ML: regression_model.py, llm_advisor.py, sharpe_utils.py
â”œâ”€â”€ static/, templates/        # Frontend: HTML, JS, CSS, Charts
â”œâ”€â”€ update_gainers.py          # Scraping der Top Gainers
â”œâ”€â”€ update_news.py             # Scraping der Finanznews
â”œâ”€â”€ analyze_sentiment.py       # Sentimentanalyse (lokal)
â”œâ”€â”€ compute_avg_sentiment.py   # Sentiment-Mittelwert aggregieren
â”œâ”€â”€ uploads/                   # CSV-Upload Ordner
â”œâ”€â”€ logs/, models/, images/    # Lokale Modelle, Logs, Beraterbilder
â”œâ”€â”€ Dockerfile, .env           # Container + Secrets
â””â”€â”€ requirements.txt           # Python-AbhÃ¤ngigkeiten


ğŸš€ Deployment & Automation
Ich habe GitHub Actions erstellt, um:

Scraping zu automatisieren (2x tÃ¤glich: 10:00 und 18:00)

Analyse-Skripte auszufÃ¼hren (Sentiment, avg Score, etc.)

Tests automatisch zu starten (pytest)

FÃ¼r Docker:

Ich habe ein funktionierendes Image gebaut (Dockerfile)

Das lÃ¤uft lokal mit Port 5151

Das Azure Deployment ist vorbereitet (Secrets gesetzt), aber noch in Arbeit


ğŸ“ Fazit
Dieses Projekt war mehr als nur ein Uni-Projekt.
Es war mein Einstieg in die Welt von Python, KI, Webentwicklung und DevOps.

Ich habe alles selbst gebaut â€“ mit UnterstÃ¼tzung von ChatGPT, viel Trial & Error,
und vor allem: mit viel Geduld.

Ich bin stolz auf mein Ergebnis.
Und wer weiÃŸ â€“ vielleicht wird Otto bald mein echter Berater ğŸ˜‰

Merci fÃ¼rs Lesen â€“ und danke an alle, die mich unterstÃ¼tzt haben.
Falls du dein Portfolio optimieren willstâ€¦ frag einfach mein Modell ğŸ˜„

## PersÃ¶nliche Reflexion
Ich habe bei der Erstellung meines Projekts den Fehler gemacht, dass ich nie die Schritte des Einsatzes meines Projekts und die Ausgaben meines Templates in VSC fÃ¼r das Docking, den Einsatz usw. fotografiert habe. Dies war eine Strafe fÃ¼r mein Lernjournal. 
